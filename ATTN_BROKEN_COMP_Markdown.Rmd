---
title: "predictions_attention"
author: "may"
date: "June 29, 2017"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Libraries:
```{r}
library(dplyr)
library(lme4)
library("aods3")     ## overdispersion diagnostics
library("bbmle")     ## AICtab
library("pbkrtest")  ## parametric bootstrap
library(car)

```

##GOTTA FIX PRIMARY STIM CODING:


```{r}
attn_habit_3$primary_stim<- attn_habit_3$trial_name_2
attn_habit_3$primary_stim<-recode(attn_habit_3$primary_stim, t_ra_t = "ts")
attn_habit_3$primary_stim<-recode(attn_habit_3$primary_stim, de_t_de = "de", tc_ts_tc = "t2c")
attn_habit_3$primary_stim<-recode(attn_habit_3$primary_stim, tc_ts_tc = "t2c")
attn_habit_3$primary_stim<-recode(attn_habit_3$primary_stim, t_de_t = "ts")

attn_habit_3$primary_stim<-recode(attn_habit_3$primary_stim, tia_tib_tia = "t1c")
attn_habit_3$primary_stim<-recode(attn_habit_3$primary_stim, rt_rra_rt = "rts")
attn_habit_3$primary_stim<-recode(attn_habit_3$primary_stim, ts_tc_ts = "ts")
attn_habit_3$primary_stim<-recode(attn_habit_3$primary_stim, rra_rt_rra = "rra")
attn_habit_3$primary_stim<-recode(attn_habit_3$primary_stim, ra_t_ra = "ra")

```

Scale numeric predictors:
```{r}

#######Ok, trying to fix hessian convergence issues. 
#try to scale numeric predictors (don't think this will work for me but whatever)
#so I am centering the call numbers around 0 and making the variance normal. 
attn_habit_3$scaled_call_num<- scale(attn_habit_3$call_num, center=TRUE, scale=TRUE)  #scaling call number
plot(attn_habit_3$scaled_call_num, attn_habit_3$call_num)

#also going to center call_num_2, which won't have the weird gaps that are weird
attn_habit_3$scaled_call_num_2<- scale(attn_habit_3$call_num_2, center=TRUE, scale=TRUE)  #scaling call number
plot(attn_habit_3$scaled_call_num_2, attn_habit_3$call_num_2) #this one won't have weird arbitrary gaps
```
## Predictions

1. comparing models with and without intercepts, with call as grouping and with set as grouping. 
All of the following in this chunk are not scaled:
```{r}

mm1<- glmer(all_tw_call ~ call_num + call_num:trial_name_2 + (trial_number| Bat_ID), data= attn_habit_3, family="poisson") #run model
smm1<- summary(mm1)  #make summary
smm1
mm1a<- glmer(all_tw_call ~ call_num_2 + call_num_2:trial_name_2 + (trial_number| Bat_ID), data= attn_habit_3, family="poisson") #trying model with a different coding of call number. 
smm1a<- summary(mm1a)  #make summary
smm1a

mm1b <- glmer(all_tw_call ~ call_num  + trial_name_2 + call_num:trial_name_2 + (trial_number| Bat_ID), data= attn_habit_3, family="poisson") #with trial_name_2 as main effect
smm1b<- summary(mm1b)  #make summary
smm1b

mm1c <- glmer(all_tw_call ~ call_num  + trial_name_2 + call_num:trial_name_2 - 1 + (trial_number| Bat_ID), data= attn_habit_3, family="poisson") #run model with trial name as main effect and no intercept
smm1c<- summary(mm1c)  #make summary
smm1c

mm1d <- glmer(all_tw_call ~ call_num  + primary_stim + call_num:primary_stim + (trial_number| Bat_ID), data= attn_habit_3, family="poisson") #run model
smm1d<- summary(mm1d)  #make summary
smm1d # model with trial as main effect, no intercept, primary stim as group 

mm1e <- glmer(all_tw_call ~ call_num  + primary_stim + call_num:primary_stim + (1| Bat_ID), data= attn_habit_3, family="poisson") #run model
smm1e<- summary(mm1d)  #make summary
smm1e # same as mm1d but w/o trial number to see effect on hessian convergence


mm1_5<- glmer(all_tw_call ~ call_num + call_num:trial_name_2 -1 + (trial_number| Bat_ID), data= attn_habit_3, family="poisson") #run model
smm1_5<- summary(mm1_5)  #make summary
smm1_5  #

mm1epsilon <- glmer(all_tw_call ~ call_num  + primary_stim + call_num:primary_stim + (1| Bat_ID), data= attn_habit_3, family="poisson")
smm1epsilon<- summary(mm1epsilon)  #make summary
smm1epsilon
#######Ok, trying to fix hessian convergence issues. in next chunk
```


Scaled models:


```{r}
#run model with scaled numeric variable, using 1.1...1.5 call_num scale
mm1f <- glmer(all_tw_call ~ scaled_call_num  + primary_stim + scaled_call_num:primary_stim + (1| Bat_ID), data= attn_habit_3, family="poisson")
smm1f<- summary(mm1f)  #make summary
smm1f


#run model with regular integer scale
mm1g <- glmer(all_tw_call ~ scaled_call_num_2  + primary_stim + scaled_call_num_2:primary_stim + (1| Bat_ID), data= attn_habit_3, family="poisson") #run model with scaled numeric variable, using scaled call nums from 1-~35 scale
smm1g<- summary(mm1g
                )  #make summary
smm1g

#run model with the  regular integer call num scale, this time without intercepts
mm1h <- glmer(all_tw_call ~ scaled_call_num  + primary_stim + scaled_call_num:primary_stim -1 + (1| Bat_ID), data= attn_habit_3, family="poisson") #run model with scaled numeric variable, using scaled call nums from 1.1...1.5 scale
smm1h<- summary(mm1h)  #make summary
smm1h

## So basically, scaling the call number to normal does help just a little bit, and is generally a good thing to do. 
#BUt still not converging, what if I add trial_number back in (full model)
#run model with the  decimal call num scale, this time without intercepts:

mm1i <- glmer(all_tw_call ~ scaled_call_num  + primary_stim + scaled_call_num:primary_stim -1 + (trial_number| Bat_ID), data= attn_habit_3, family="poisson") #run model with scaled numeric variable, using scaled call nums from 1.1...1.5 scale
smm1i<- summary(mm1i)
smm1i



#1 centered and scaled
#and with integer scale?    VVVVVVVVVVVVV
#default optimizer, mix of bobyqa and nelder-mead
mm1j <- glmer(all_tw_call ~ scaled_call_num_2*primary_stim -1 + (trial_number| Bat_ID), data= attn_habit_3, family="poisson") #run model with scaled numeric variable, using scaled call nums from integer scale
smm1j<- summary(mm1j)
smm1j  
## not converging

##Troubleshooting, following: 
## critera outlined by the amazing Ben Bolker:
## "Assessing Convergence for Fitted models, convergence {lme4}

##https://stackoverflow.com/questions/33670628/solution-to-the-warning-message-using-glmer
  "Since the likelihood differs by <0.1 between the model fits, and the largest relative differences in the parameters are of the order of about 10^(-4), I would say that you have successfully demonstrated that the warning is a false positive and you can proceed with your initial model."

## https://bbolker.github.io/mixedmodels-misc/glmmFAQ.html ##I use "gold standard" of comparing diff optimizers
  
 #1 center and scale (check) 
#2, check for singularity:
diag.vals <- getME(mm1j,"theta")[getME(mm1j,"lower") == 0]
any(diag.vals < 1e-6) # FALSE , no singularity

##3. recompute gradient and Hessian with Richardson extrapolation
devfun <- update(mm1j, devFunOnly=TRUE)
if (isLMM(mm1j)) {
    pars <- getME(mm1j,"theta")
} else {
    ## GLMM: requires both random and fixed parameters
    pars <- getME(mm1j, c("theta","fixef"))
}
if (require("numDeriv")) {
    cat("hess:\n"); print(hess <- hessian(devfun, unlist(pars)))
    cat("grad:\n"); print(grad <- grad(devfun, unlist(pars)))
    cat("scaled gradient:\n")
    print(scgrad <- solve(chol(hess), grad))
}
## compare with internal calculations:
mm1j@optinfo$derivs 

#So it looks to me that all the scaled gradients in the shorthand calculations are much larger than the lme4 default internal calculations, which would be one reason why model doesn't converge.

## 4. restart the fit from the original value (or
## a slightly perturbed value):
mm1j.restart <- update(mm1j, start=pars) #this also seems to fix the problem. Gets stuck on an optimum?

## 5. try all available optimizers (from Bolker)/ "gold standard"

  source(system.file("utils", "allFit.R", package="lme4"))
  fm1.all <- allFit(mm1j)
  ss <- summary(fm1.all)
  ss$ fixef               ## extract fixed effects #differ at most on the order od 10^-3
  ss$ llik                ## log-likelihoods #check, differ by less than .1
  ss$ sdcor               ## SDs and correlations
  ss$ theta               ## Cholesky factors
  ss$ which.OK            ## which fits worked


  ## This suggests that the model is appropriate, and the convergence warnings are a false positive, bc the different optimizers produce very similar results-- fixed effects that differ on the scale of 10^-3 or less, and identical log-likelihoods (<.1)
 
  ## Here on out I am going to use the bobyqa, though any can be used, bc they all show the name thing. (bootstrap will be vetter if I pick one that converges more, bc more will not fail. ) 
  
#bobyqa omptimizer
mm1bob <- glmer(all_tw_call ~ scaled_call_num_2*primary_stim -1 + (trial_number| Bat_ID), data= attn_habit_3, family="poisson", control=glmerControl(optimizer = "bobyqa"))
smm1bob<- summary(mm1bob)
smm1bob

#other possible optimizers: "Nelder_Mead", the default, etc, also could up the interations:
#upping the iterations (commented out)
# ss <- getME(mm1j,c("theta","fixef"))
# mm1jx <- update(mm1j,start=ss,control=glmerControl(optCtrl=list(maxfun=1e4)))
# smm1jx<-summary(mm1jx)
# smm1jx #fine with 10,000 iterations, doesn't need the max, 20,000 iterations

```
  
  
ANOVA:
Really interested in: does the habituation to calls vary by treatment? e.g. is the call_num/treatment interaction significant

We need type 2 or type 3 anova bc type w doesn't make as much sense here (don't want to move through variables and varience sequentially)

```{r}
#anova using car package for type 3 anova
Anova(mm1bob, type=3) # This just demonstrates that is appropriate to further look for an interaction between  call number and primary stimulus. 

```
This justifies that different treatments change at different rates, can look for posthocs. 
So now on to post hoc demonstrating that the different fixed effects are different from one another 
```{r}

###I DONT KNOW WHY I WONT CONVERGE WHEN BOOTSTAPPED, here it is anyway
bootMer()

boot_habit<-bootMer(x=update(mm1j,start=ss,control=glmerControl(optCtrl=list(maxfun=1e4))),FUN=fixef,nsim=1)
mm1j.ci<- boot.ci(boot.out = boot_habit, type = "perc")

## just making a lot of confidence intervals


c0 <- confint(mm1jx,method="Wald")
```
ran with no errors
```{r}
c1 <- confint(mm1jx)
```
ran with around 78 errors:
1: failure to converge in 10000 evaluations
2:unexpected decrease in profile: using minstep
3:bad spline fit for primary_stimrra: falling back to linear interpolation (or whatever treatment)
  
```{r}
#c2 <- confint(mm1jx,method="boot")  #can't run without way too many failed convergences
c2<- confint(mm1jx, type="bca")
```
Warnings:
failure to converge in 10000 evaluations : 43 
expected decrease in profile: using minstep:27
non-monotonic profile for primary_stimde: 6
bad spline fit for primary_stimt1c: falling back to linear interpolation: 6

total: 82
```{r}
library(effects)
c3 <- with(effect("scaled_call_num_2*primary_stim",mm1jx),cbind(lower,upper))
c4 <- with(summary(lsmeans(mm1jx,spec="scaled_call_num_2*primary_stim")),cbind(lower.CL,upper.CL))
tmpf <- function(method,val) {
    data.frame(method=method,
               v=names(fixef(mm1jx)),
               setNames(as.data.frame(tail(val,14)),
                        c("lwr","upr")))
}
library(ggplot2); theme_set(theme_bw())
allCI <- rbind(tmpf("lme4_wald",c0),
      tmpf("lme4_prof",c1),
      tmpf("lme4_bca",c2),
      tmpf("effects",c3))
               
confint_comp<- ggplot(allCI,aes(v,ymin=lwr,ymax=upr,colour=method))+
    geom_linerange(position=position_dodge(width=0.8)) +
                     theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1))

confint_comp

ggsave("pastes_confint_mac.png",width=10)

boot_habit2<-bootMer(x=mm1jx,FUN=fixef,nsim=1000)

c0df<- as.data.frame(c0)
c1df<- as.data.frame(c1)
c2df<- as.data.frame(c2)
c3df<- as.data.frame(c3)

write.csv(c0df, file="c0_boot_ouput_mac.csv")
write.csv(c1df, file="c1_boot_output_mac.csv")
write.csv(c2df, file="c2_boot_output_mac.csv")
write.csv(c3df, file="c3_boot_output_mac.csv")

```
trying to do post-hoc comparisons to compare if the interactions are different from one another 

```{r}
#trying to do post-hoc comparisons to compare if the interactions are different
library(multcomp)
multiple_comp<- lsmeans(mm1jx,  ~ primary_stim :  scaled_call_num_2) #don't think this morks
multiple_comp<- glht(mm1jx, mcp(scaled_call_num_2:treatment*primary_stim ="Tukey", interaction_average = TRUE  ))

# following advice from https://stats.stackexchange.com/questions/5250/multiple-comparisons-on-a-mixed-effects-model
```
messing around with making bootstap make sense

```{r}
#second case more complex design with two crossed RE and a poisson response

 
#for GLMMs we have to back-transform the prediction after adding/removing the SE
newdat<-data.frame(x=seq(1,14,length=14))
mm<-model.matrix(~x,newdat)
y<-mm%*%fixef(mm1jx)
pvar1 <- diag(mm %*% tcrossprod(vcov(m),mm))
tvar1 <- pvar1+VarCorr(m)$f1[1]+VarCorr(m)$f2[1]  ## must be adapted for more complex models
newdat <- data.frame(
  x=newdat$x,
  y=exp(y),
   plo = exp(y-1.96*sqrt(pvar1))
  , phi = exp(y+1.96*sqrt(pvar1))
  , tlo = exp(y-1.96*sqrt(tvar1))
  , thi = exp(y+1.96*sqrt(tvar1))
)
 
#second version with bootMer
predFun<-function(.) exp(mm%*%fixef(.)) 
bb<-bootMer(m,FUN=predFun,nsim=200)
bb_se<-apply(boot_habit$t,2,function(x) x[order(x)])
newdat$blo<-bb_se[1,]
newdat$bhi<-bb_se[2,]
newdatz<-data.frame(seq(1,14, length=14))
newdat$names <- names(fixef(mm1jx))

newdatz
```

effects(scaled_call_num_2*primary_stim, mm1j) #this isn't called right
## This is the best model
## It is a full model, has all the main effects of call number and of the interaction effects
## It has both trial number and subject as random effects
## It converges
## It's "time" value is normalized and scaled (centered, etc), which is good bc the names for time are arbitrary anyway
## We used the call number scale that makes the most sense, isn't interpreted as different weights of differences between each chunk. 



## This is just for me to look at what the values of the slope are for the interactions:
smm1jnames<- rownames(smm1j$coefficients)
Estimate1<- smm1j$coefficients + smm1j$coefficients[1,1] #adding the main effect of call number, using De as reference. 
cbind(smm1jnames, as.numeric(Estimate1))


##Hookay. So now I have a model with some values that are things. I can try to estimate the confidence intervals now, I believe. 
#These are estimated confindence intervals:
confint_full_model<- confint(mm1j, type="bca")
CFM<- confint_full_model

#Now to make a dataframe with the fixed effect values of the interactions, and their confidence intervals

#now I am going to try to make a dataframe including only the interaction effects, and really, only the interaction effects when added to the reference value, so the true values of each of the interactions
# fixef_mm1j <- cbind(fixef(mm1j))
# fixef_mm1j_ie<-rbind(fixef_mm1j[1,],cbind(fixef_mm1j[9:14,] + fixef_mm1j[1,])) #deleting the no interaction effect fixed effects
# colnames(fixef_mm1j_ie)<- "fixeffects"
# fixef_mm1j_ie     
#       
# #Doing the same to the confidence intervals
# conf_frame<-rbind(CFM[4,], (CFM[12:17,] + CFM[4,])) #making all interactions true values by adding the main effect of call number which is referenced to de to the other values
# rownames(conf_frame)[1]<- "scaled_call_num_2:primary_stimde" #adding rowname to the first column
# TMT<-c("De", "Ra", "Rra", "Rt1c", "T1c", "T2c", "Ts") 
# row.names(conf_frame)<-NULL
# interaction_cis<-as.data.frame(cbind(TMT, fixef_mm1j_ie, conf_frame)) #data frame with the 95%cis for the interactions bectween call number and treatments
# interaction_cis$`2.5 %`<-as.numeric(as.character(interaction_cis$`2.5 %`))
# interaction_cis$`97.5 %`<-as.numeric(as.character(interaction_cis$`97.5 %`))
# interaction_cis$fixeffects<-as.numeric(as.character(interaction_cis$fixeffects))
# colnames(interaction_cis)<- c("TMT", "fixeffects", "lower_ci", "upper_ci")
# interaction_cis$midval<- apply(interaction_cis[,3:4],1, mean)
# row.names(interaction_cis) <- NULL 
# interaction_cis


### Alternatively, just use Tidy?
Mm1j_tidy<- tidy(mm1j, conf.int=TRUE)
#makes lovely dataframe with all my lovely values

#cleaning a bit:
MM1j_ceoffs<- Mm1j_tidy[-2:-8,]
MM1j_coeffss<- MM1j_ceoffs[-8:-10,]
MM1j_coeff3<- cbind(TMT, MM1j_coeffss)

#now to adjust for reference value. Make new columns adding reference to the interactions

MM1j_coeff3$slopes<- MM1j_coeff3[,3] + 0.05044288 #adding value of De/reference to the slopes
MM1j_coeff3$slopes[1]<-0.05044288 #fixing the effect for de
MM1j_coeff3$conf.low.adj<-MM1j_coeff3$conf.low + 0.05044288 #adding value of De/reference to the low.ci
MM1j_coeff3$conf.low.adj[1]<- -0.08649563 #fixing high ci for de

MM1j_coeff3$conf.high.adj<-MM1j_coeff3$conf.high + 0.05044288 #adding value of De/reference to the low.ci
MM1j_coeff3$conf.high.adj[1]<- 0.1873814 #fixing high ci for de

```
Now to graph these

```{r}
#graphing the slopes and their CI's

plot_ci_slopes<- ggplot(data= MM1j_coeff3, aes(x=TMT, y= slopes)) +
geom_point() +
geom_errorbar(ymin = MM1j_coeff3$conf.low.adj  , ymax = MM1j_coeff3$conf.high.adj )
plot_ci_slopes

plot_ci_slopes<- ggplot(data=interaction_cis,  aes(x=(lower_ci+upper_ci/2))) +
geom_errorbar(ymin = interaction_cis$lower_ci  , ymax = interaction_cis$upper_ci )

plot_ci_slopes
```
Show in New WindowClear OutputExpand/Collapse Output
estimate
<dbl>
std.error
<dbl>
statistic
<dbl>
p.value
<dbl>
conf.low
<dbl>
conf.high
<dbl>
group
<chr>
0.05044288	0.06986787	0.7219753	4.703096e-01	-0.08649563	0.1873814	fixed
-1.07186301	0.12024991	-8.9136282	4.938922e-19	-1.30754850	-0.8361775	fixed
-0.86674770	0.09873082	-8.7788968	1.650859e-18	-1.06025655	-0.6732388	fixed
-0.41473021	0.10785571	-3.8452320	1.204385e-04	-0.62612350	-0.2033369	fixed
-0.25967210	0.08068247	-3.2184451	1.288877e-03	-0.41780684	-0.1015374	fixed
-0.17686792	0.09734415	-1.8169343	6.922717e-02	-0.36765894	0.0139231	fixed
-0.36817611	0.10992532	-3.3493293	8.100745e-04	-0.58362578	-0.1527264	fixed
7 rows | 3-9 of 8 columns

##################



names<-c("smm1$AICtab", "smm1_5$AICtab", "smm2$AICtab", "smm2_5$AICtab", "smm3$AICtab", "smm3_5$AICtab", "smm4$AICtab", "smm4_5$AICtab, "smm5")
AIC_comp<- rbind( smm1$AICtab, smm1_5$AICtab, smm2$AICtab, smm2_5$AICtab, smm3$AICtab, smm3_5$AICtab, smm4$AICtab, smm4_5$AICtab, smm5)
AIC_comp<- cbind(names, AIC_comp)
AIC_comp

coeff_comp<- cbind(smm1$coefficients, smm1_5$coefficients, smm2$coefficients, smm2_5$coefficients, smm3$coefficients, smm3_5$coefficients, smm4$coefficients, smm4_5$coefficients)
coeff_comp




```



```{r}
library(lme4)
library(boot)
#2.5 #this adds call number as a main effect, but doesn't include the main effect of trial type
m2_5<- glmer(all_tw_call ~ call_num + call_num:trial_name_2 + trial_number + (1| Bat_ID), data= attn_habit_3, family="poisson")
sm25<- summary(m2_5)
sm25

boot_habit<-bootMer(x=sm25,FUN=fixef,nsim=200)
boot.ci(b_par,type="perc",index=1)




```